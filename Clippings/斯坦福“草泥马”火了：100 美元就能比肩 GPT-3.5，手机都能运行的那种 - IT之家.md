# 斯坦福“草泥马”火了：100 美元就能比肩 GPT-3.5，手机都能运行的那种 - IT之家
[斯坦福“草泥马”火了：100 美元就能比肩 GPT-3.5，手机都能运行的那种 - IT之家](https://www.ithome.com/0/679/783.htm) 

 一夜之间，大模型界又炸出个 big news！

斯坦福发布 **Alpaca**（羊驼，网友口中的“草泥马”）：

> 只花 100 美元，人人都可微调 Meta 家 70 亿参数的 LLaMA 大模型，效果竟可比肩 1750 亿参数的 GPT-3.5（text-davinci-003）。
> 
> 而且还是单卡就能运行的那种，甚至树莓派、手机都能 hold 住！

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/bd6416de-b184-4ebd-b9a6-75e16c73c503.png?raw=true)

还有一个更绝的“骚操作”。

研究所涉及到的数据集，是斯坦福团队花了不到 500 美元用 OpenAI 的 API 来生成的。

所以整个过程下来，就等同于 GPT-3.5 自己教出了个旗鼓相当的对手 AI。

（薅羊毛高手……）

然后团队还说，用大多数云计算平台去微调训练好的模型，成本也不到 100 美元：

> 复制一个 GPT-3.5 效果的 AI，很便宜，很容易，还很小。

而且团队还把数据集（秒省 500 刀）、代码统统都给开源了，这下子人人都能去微调个效果炸裂的对话 AI：

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/e7d059b9-d85e-4aee-8795-6dcd29212db2.jpeg?raw=true)

项目在 GitHub 发布才半天时间，便已经狂揽 1800 + 星，火爆程度可见一斑。

Django 联合开发者甚至对斯坦福的新研究用“惊天大事”来形容：

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/06fe6b7f-202c-415c-9058-913afbb5d844.png?raw=true)

不仅如此，斯坦福团队还搞了个 demo，在线可玩的那种。

话不多说，我们现在就来看看这个“草泥马”的效果。

比肩 davinci-003 的草泥马 Aplaca
--------------------------

在斯坦福官方的演示中，他们先小试牛刀地提了一个问题：

> 什么是羊驼？它和美洲驼的区别是什么？

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/186abce1-6021-48d4-aef5-036b8f0a494b.png?raw=true)

草泥马 Aplaca 给出的答案较为干练：

> 羊驼是一种小型骆驼科动物，原产于秘鲁、玻利维亚、厄瓜多尔和智利；它比美洲驼小，羊毛更细，也没有驼峰。

而后又简单的介绍了二者群居生活的不同。

同样的问题若是交给 ChatGPT（GPT3.5-turbo），则答案就不会像草泥马 Aplaca 那般简洁：

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/ef4b8e66-3eee-4058-b7eb-f575de70a3f7.png?raw=true)

对此，团队给出的解释是：

> Alpaca 的答案通常比 ChatGPT 短，反映出 text-davinci-003 的输出较短。

而后团队演示了让草泥马 Alpaca **写邮件**：

> 写一封 e-mail 祝贺被斯坦福大学录取的新生，并提到你很高兴能亲自见到他们。

草泥马 Alpaca 对于这个任务也是信手拈来，直接给出了一个像模像样的邮件模板：

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/de1074fc-1fc1-4c5d-8a75-4b6a0afad52e.png?raw=true)

难度再次进阶，团队这次提出了让草泥马 Alpaca **写论文摘要**的需求：

> 写一篇经过深思熟虑的机器学习论文摘要，证明 42 是训练神经网络的最优 seed。

草泥马 Alpaca 给出的答案从内容上来看，非常符合大多数论文的摘要形式：试图回答什么问题、用了什么方法、结果如何，以及未来展望。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/5c577dbf-9061-48c4-ad67-9ea76e91742d.png?raw=true)

当然，也有迫不及待的网友亲自下场试验，发现草泥马 Alpaca 写代码也是不在话下。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/4a63a7ee-a213-41fb-b9d6-e28d949ea39a.png?raw=true)

不过即便草泥马 Alpaca 能够 hold 住大部分问题，但这并不意味着它没有缺陷。

例如团队便演示了一个例子，在回答“坦桑尼亚的首都是哪里”的问题时，草泥马 Alpaca 给出的答案是“达累斯萨拉姆”。

但实际上早在 1975 年便被“多多马”取代了。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/6ebe7a1c-bab7-4614-8d4e-407d616c917e.png?raw=true)

除此之外，若是亲自体验过草泥马 Alpaca 就会发现，它…… 巨慢：

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/e9eee5fe-1108-4cbe-8cd7-a4134ba83c17.png?raw=true)

对此，有网友认为可能是使用的人太多的原因。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/5fe30aad-be4d-4ddb-ad0e-4747dcaa9a2a.png?raw=true)

笔记本、手机、树莓派都能跑
-------------

Meta 开源的 LLaMA 大模型，刚发布几周就被大家安排明白了，单卡就能运行。

所以理论上，基于 LLaMA 微调的 Alpaca 同样可以轻松在本地部署。

没有显卡也没关系，苹果笔记本甚至树莓派、手机都可以玩。

在苹果笔记本部署 LLaMA 的方法来自 GitHub 项目 llama.cpp，使用纯 C / C++ 做推理，还专门对 ARM 芯片做了优化。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/0b247415-c060-4cf1-8f84-3cad73ea1c26.png?raw=true)

作者实测，M1 芯片的 MacBook Pro 上即可运行，另外也支持 Windows 和 Linux 系统。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/950debe2-88a2-4b3a-8110-33147ab6e9dc.png?raw=true)

还是这个 C++ 移植版本，有人成功在 4GB 内存的树莓派 4 上成功运行了 LLaMA 的 70 亿参数版本。

虽然速度非常慢，大约 10 秒生成一个 token（也就是一分钟蹦出 4.5 个单词）。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/72bb78a3-6ea3-448c-8e22-7eeb64e53c3e.png?raw=true)

更离谱的是仅仅 2 天之后，有人把 LLaMA 模型量化压缩（权重转换成更低精度的数据格式）后成功在 Pixel 6 [安卓](https://android.ithome.com/)手机上运行（26 秒一个 token）。

Pixel 6 使用谷歌自研处理器 Google Tensor，跑分成绩在骁龙 865 + 到 888 之间，也就是说新一点的手机理论上都能胜任。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/e5f2fc3f-6945-468f-8b4e-25f59c0b0fcf.png?raw=true)

微调数据集也开源
--------

斯坦福团队微调 LLaMA 的方法，来自华盛顿大学 Yizhong Wang 等去年底提出的 Self-Instruct。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/8b559a58-99ce-474a-ad6b-39b5627b2e30.png?raw=true)

以 175 个问题作为种子任务，让 AI 自己从中组合出新的问题以及生成配套答案实例，人工过滤掉低质量的，再把新任务添加到任务池里。

所有这些任务，之后可以采用 InstructGPT 的方法让 AI 学会如何遵循人类指令。

套娃几圈下来，相当于让 AI 自己指导自己。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/e692c6b9-13be-45d2-9fd9-33791019b8b4.png?raw=true)

斯坦福版 Alpaca，就是花了不到 500 美元使用 OpenAI API 生成了 5.2 万个这样的示例搞出来的。

这些数据同样开源了出来，并且比原论文的数据多样性更高。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/1e5c795a-a7ee-479b-884a-2972918101d5.png?raw=true)

同时还给出了生成这些数据的代码，也就是说如果有人还嫌不够，可以再去自行扩充微调数据，继续提高模型的表现。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/3f7aa801-f60d-4d94-a7a0-4b567b745c2f.png?raw=true)

微调代码也会在 HuggingFace 官方支持 LLaMA 后放出。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/e761acda-ba26-4a0c-997f-46c6c691a2a3.png?raw=true)

不过 Alpaca 最终的模型权重需要 Meta 许可才能发布，并且继承了 LLaMA 的非商用开源协议，禁止任何商业用途。

并且由于微调数据使用了 OpenAI 的 API，根据使用条款也禁止用来开发与 OpenAI 形成竞争的模型。

One More Thing
--------------

还记得 AI 绘画的发展历程吗？

2022 年上半年还只是话题热度高，8 月份 Stable Diffusion 的开源让成本下降到可用，并由此产生爆炸式的工具创新，让 AI 绘画真正进入各类工作流程。

语言模型的成本，如今也下降到了个人电子设备可用的程度。

最后还是由 Django 框架创始人 Simon Willison 喊出：

> 大语言模型的 Stable Diffusion 时刻到了。

![](https://github.com/ustczzh/MyClippings/blob/main/Images/2023-3-15%2013-46-16/5468f9cc-0744-4c6d-a077-6cdbda4cb0ba.png?raw=true)

本文来自微信公众号：[量子位 （ID：QbitAI）](https://mp.weixin.qq.com/s/8SP6sKQ21YxeFQe3rwOh8A)，作者：梦晨 金磊